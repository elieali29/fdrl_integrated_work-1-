# -*- coding: utf-8 -*-
"""FDRL Integrated work

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Zy0sWfJNKWCMM0q3bJui8I61Vc7T4M93

# Federated Learning with TensorFlow
"""

from google.colab import drive
drive.mount('/content/drive')

"""#### This notebook presents a simple Federated Learning example / application on developing a Machine Learning model as an Intrusion Detection System for defending against Cyberattacks using distributed and private data.
#### This example uses Docker containers as independent workers / clients for performing the client model training on the limited and private local client data.
#### This example was developed as part of the research conducted at MetaMind Innovations in the framework of the [AI4CYBER](http://metamind.gr/portfolio-items/ai4cyber-horizon-europe/) project.

## Set Up TFF Environment
"""

!pip install keras-core
!pip install wurlitzer
!pip install adamp
!pip install scipy>=1.10.0
!pip install dill<0.3.2
!pip install numpy<1.25.0
!pip install protobuf<4
!pip install pyarrow<10.0.0
!pip install jax>=0.4.16
!pip install packaging>=23.0
!pip install typing-extensions>=4.8.0
!pip install google-api-core<2.0.0
!pip install shapely>=2.0.1
!pip install sqlalchemy>=2.0
!pip install jupyter-lsp>=2.0.0
!pip install ml-dtypes>=0.3.1
!pip install tensorflow~=2.15.0
!pip install tensorflow-text>=2.15.0,<2.16
!pip install typing-extensions>=4.6.1
!pip install matplotlib>=3.7
!pip install --force-reinstall nest-asyncio
!pip install jupyterlab~=3.6.0
#!pip install --quiet --upgrade tensorflow-federated

!pip install tensorflow-federated==0.20.0
!pip show tensorflow-federated

!pip install jaxlib==0.4.16

#!pip install --quiet --upgrade tensorflow-federated
!pip install --quiet --upgrade nest-asyncio
!pip install --quiet --upgrade pandas
!pip install --quiet --upgrade matplotlib
!pip install tensorflow-federated==0.20.0

# Commented out IPython magic to ensure Python compatibility.
import collections
import os
import pandas as pd
import tensorflow as tf

import tensorflow_federated as tff

import time
import matplotlib.pyplot as plt
from matplotlib import pyplot as plt

import nest_asyncio
nest_asyncio.apply()

# %matplotlib inline

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

"""Print a "Hello World" message through TFF to verify the proper TFF installation"""

tff.federated_computation(lambda: 'Hello, World!')()

"""## Dataset

This dataset is part of the [IEC 60870-5-104 Intrusion Detection Dataset](http://zenodo.org/record/7108614#.YzGaDtJBwUE) -- DOI: [10.1109/TII.2021.3093905](http://doi.org/10.1109/TII.2021.3093905) -- published by [ITHACA â€“ University of Western Macedonia](http://ithaca.ece.uowm.gr/).

We input the dataset path and choose which dataset to facilitate for the experimentation.

We also input the number of clients / workers that we are going to use. We can use $2 \leq N \leq 5$ individual workers.

For this example we use the CICFlowMeter dataset with capturing timeout at 180 seconds with 2 distinct workers.
"""

#path = '/kaggle/input/simple-tff'
tp = 'cic'      # Type: choose between 'cic' and 'custom'// cic means the type of dataset
tm = 180        # Timeout: choose one value from the following list [15, 30, 60, 90, 120, 180] the time out will be in one of these numbers
n_workers = 10  # #workers: choose between 2 and 10 workers (2 and 10 inclusive)

"""Perform some input value checks."""

assert tp in ('cic', 'custom'), "Wrong dataset type" # essert means to check if this is true or fales
assert tm in (15, 30, 60, 90, 120, 180), "Wrong time"
assert 2 <= n_workers <= 10, "At least 2 and at most 5 workers (docker containers) are required"

dataset = f'tests_{tp}_{tm}'

# if 'cic' in dataset:
#     n = dataset.split('_')[-1]
#     train_csv = os.path.join(os.path.join(path, dataset), f'train_{tm}_cicflow.csv')
#     test_csv = os.path.join(os.path.join(path, dataset), f'test_{tm}_cicflow.csv')
# elif 'custom' in dataset:
#     n = dataset.split('_')
#     train_csv = os.path.join(os.path.join(path, dataset), f'train_{tm}_custom_script.csv')
#     test_csv = os.path.join(os.path.join(path, dataset), f'test_{tm}_custom_script.csv')
# else:
#     raise Exception("Wrong dataset")

train_csv = "/content/drive/MyDrive/Elham/train_data.csv"
test_csv = "/content/drive/MyDrive/Elham/test_data.csv"

df_train = pd.read_csv(train_csv,nrows=10000)
df_test = pd.read_csv(test_csv)

"""Let's perform some data exploration."""

df_train.dtypes # df = dataframe It retrieves the data types of each column in the DataFrame df_train.

df_test.dtypes # It retrieves the data types of each column in the DataFrame df_test.

df_train.info()

df_test.info()

"""As a preprocessing step, we transorm the "Label" feature from string to categorical and then to numeric."""

print(df_test.columns)

print(df_train.columns)

# Convert the 'label' column to string type before applying .str.lower()
df_train['label'] = df_train['label'].astype(str).str.lower() # .astype(str): Converts the data type of the label column to strings
df_test['label'] = df_test['label'].astype(str).str.lower() # .astype(str): Converts the data type of the label column to strings

"""this code to show us the unique values in each columns"""

import pandas as pd

# Load your dataset (replace 'your_dataset.csv' with the path to your actual dataset)
df = pd.read_csv('/content/drive/MyDrive/Elham/train_data.csv')

# Print the column names
print("columns in  the dataset")
print(df.columns)

# Check the unique values in each column to find the target column
for column in df.columns:
    unique_values = df[column].unique()
    print(f"Unique values in column '{column}': {unique_values}\n")

"""this code creates a dictionary where each unique integer code (from unique_codes) is mapped to its corresponding unique label (from unique_labels).   this mapping helps to efficiently convert and interpret categorical data in a structured and consistent manner"""

unique_labels = list(df_train.label.astype('category').unique()) #  Converts the label column to the 'category' data type. This is useful for categorical data and can make certain operations more efficient
unique_codes = list(df_train.label.astype('category').cat.codes.unique())  # Converts each unique category to a unique integer code.
mapping = {unique_codes[i] : unique_labels[i] for i in range(len(unique_labels))}

mapping

import tensorflow as tf # Import tensorflow
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import collections
import pandas as pd

# Read the dataset
df_train = pd.read_csv('/content/drive/MyDrive/Elham/train_data.csv')

# Print the first few rows and column names to verify
#print(df_train.head())
#print(df_train.columns)

# Replace 'target' with the actual name of your target column
target_column = 'label'  # Update this to the correct column name if necessary

if target_column not in df_train.columns:
    print(f"Error: '{target_column}' column not found in the dataset.")
else:
    print(f"'{target_column}' column found.")

 # Split the data into features (X) and labels (y)
    X = df_train.drop(columns=[target_column])
    y = df_train[target_column]

   # Train/test split 0.2= 20% for testing and rest for training,
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    print(f"Train shape: {X_train.shape}, {y_train.shape}")
    print(f"Test shape: {X_test.shape}, {y_test.shape}")

   # Train a simple logistic regression model to classify the data based on the features and labels provided
    model = LogisticRegression(max_iter=1000) # with a maximum of 1000 iterations
    model.fit(X_train, y_train)

      # Predict and calculate accuracy
    predictions = model.predict(X_test)
    print("Accuracy:", accuracy_score(y_test, predictions))

     # Federated Learning Setup
    n_workers = 10
    n_samples = int(len(df_train) / n_workers)
    print(f"Samples per worker: {n_samples}, Total samples: {len(df_train)}")
    assert n_samples > 0, "Each worker must be assigned at least one data point"

    client_data = [df_train.sample(n=n_samples) for _ in range(n_workers)]
    for i, data in enumerate(client_data):
        print(f"Worker {i+1} data shape: {data.shape}")

   # Preprocessing function
n_epochs = 50
shuffle_buffer_size = df_train.shape[0]
batch_size = 46
prefetch_buffer_size = 1


#find the perferct batch size
#batch_sizes = [16, 32, 64, 128]
#for batch_size in batch_sizes:
    # Preprocessing and training code here
 #   print(f"Training with batch size: {batch_size}")
 # this is the end of finding the best batch size Train your model and evaluate performance


def preprocess(dataframe):
    def map_fn(x, y): # Modify map_fn to accept two arguments
        return collections.OrderedDict(
            x=tf.cast(x, tf.float64),
            y=tf.cast(tf.reshape(y, shape=(-1, 1)), tf.int64)
        )

    return tf.data.Dataset.from_tensor_slices((dataframe.iloc[:, :-1].values, dataframe.iloc[:, -1].values)).repeat(n_epochs).shuffle(
        shuffle_buffer_size).batch(batch_size).map(map_fn).prefetch(prefetch_buffer_size)

client_data_processed = [preprocess(client_data[i]) for i in range(n_workers)]

print("Preprocessing complete.")

"""Above result >>> Explanation
The number 204,313 is the result of dividing the total number of samples in df_train (which appears to be 2,043,130) by the number of workers (10). This ensures that each worker gets an equal share of the data. If you see the output as:

to imporve the accuracy

Now, we remove the features which do not assist with training a ML model.
"""

import pandas as pd
from sklearn.model_selection import train_test_split


## Me trying to enhance the accuracy
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping
import pandas as pd
from sklearn.model_selection import train_test_split

# Define the input shape and number of classes based on your dataset
input_shape = (68,)  # e.g., (784,) for 28x28 pixel images flattened
num_classes = 2   # e.g., 10 for 10 classes

# Define your model
model = tf.keras.Sequential([
    tf.keras.layers.Dense(128, activation='relu', input_shape=input_shape),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(num_classes, activation='softmax')
])

# Compile your model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Early stopping callback
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Read the dataset
df_train = pd.read_csv('/content/drive/MyDrive/Elham/train_data.csv')
print(f"Dataset shape: {df_train.shape}")  # Ensure the dataset shape is as expected
print(df_train.columns) # Print the columns to see the available column names

# Replace 'target' with the actual name of your target column
target_column = 'label' # Replace with the correct column name from the printed list

# Split data into features and labels
X = df_train.drop(target_column, axis=1).values  # Use the correct target column name
y = df_train[target_column].values

# Split into train and validation sets
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)


# Define your training parameters
n_epochs = 50
batch_size = 32   #64
shuffle_buffer_size = len(X_train)  # Use length of training data
prefetch_buffer_size = 1    #50

# Data pipeline example (using TensorFlow Data API)
train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))
train_dataset = train_dataset.shuffle(shuffle_buffer_size).batch(batch_size).prefetch(prefetch_buffer_size)

val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))

## Me trying

# Read the dataset
df_train = pd.read_csv('/content/drive/MyDrive/Elham/train_data.csv')
print(f"Dataset shape: {df_train.shape}")  # Ensure the dataset shape is as expected

# Define number of workers
n_workers = 10
n_samples = int(df_train.shape[0] / n_workers)
print(f"Samples per worker: {n_samples}, Total samples: {df_train.shape[0]}")
assert n_samples > 0, "Each worker must be assigned at least one data point"




#Set training parameters
n_epochs =  50    #20
shuffle_buffer_size = df_train.shape[0]
batch_size = 32  #10000
prefetch_buffer_size = 1

# Define input and output shapes
input_shape = df_train.shape[1] - 1
unique_codes = df_train.iloc[:, -1].unique()  # Example to get unique target values
output_shape = len(unique_codes)

print(f"Input shape: {input_shape}, Output shape: {output_shape}")

# Process the data
X = df_train.iloc[:, :-1]
y = df_train.iloc[:, -1]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"Train shape: {X_train.shape}, {y_train.shape}")
print(f"Test shape: {X_test.shape}, {y_test.shape}")

tp = 'cic'
if tp == 'cic':
    # Check if columns exist before dropping
    columns_to_drop = ['Flow ID', 'Src IP', 'Src Port', 'Dst IP', 'Dst Port', 'Protocol', 'Timestamp']
    existing_columns_train = df_train.columns
    existing_columns_test = df_test.columns

    columns_to_drop_train = [col for col in columns_to_drop if col in existing_columns_train]
    columns_to_drop_test = [col for col in columns_to_drop if col in existing_columns_test]

    train = df_train.drop(columns=columns_to_drop_train)
    test = df_test.drop(columns=columns_to_drop_test)
else:
    train = df_train
    test = df_test



"""Each worker will be assigned a subset of the dataset with $\lfloor {M \over N} \rfloor$ data points."""

n_samples = int(df_train.shape[0] / n_workers)
print(n_samples,df_train.shape[0])
assert n_samples > 0, "Each worker must be assigned at least one data point"

"""As a preprocessing step, for every client individually, we randomly choose N samples from the client's subset, flatten and shuffle it."""

n_epochs = 50  #20
shuffle_buffer_size = df_train.shape[0]
batch_size = 32 #10000
prefetch_buffer_size = 1 #50
input_shape = df_train.shape[1] - 1 # Use df_train instead of fd_train
output_shape = len(unique_codes)

def preprocess(dataframe):

    """Flatten a batch `pixels` and return the features as an `OrderedDict`."""
    def map_fn(dataset):
        return collections.OrderedDict(
            x=tf.cast(dataset[:,:-1], tf.float64),
            y=tf.cast(tf.reshape(dataset[:,-1], shape=(-1, 1)), tf.int64)
        )

    return tf.data.Dataset.from_tensor_slices(dataframe).repeat(n_epochs).shuffle(
        shuffle_buffer_size).batch(batch_size).map(map_fn).prefetch(prefetch_buffer_size)
import collections
import tensorflow as tf

# Assuming 'df_train' is your training DataFrame
client_data = [preprocess(df_train.sample(n=n_samples)) for _ in range(n_workers)]

client_data

for i in range(n_workers):
    print(f"Worker {i+1} data contains {len(client_data[i])} training points")

"""Let's perform some statistical analysis on the difference in the number of samples for each digit in each client dataset."""

!pip install matplotlib

import matplotlib.pyplot as plt
import collections
import pandas as pd
import tensorflow as tf

# Load your training data
train = pd.read_csv('/content/drive/MyDrive/Elham/train_data.csv')

n_workers = 10
n_samples = 100             # 100 individual data points from your dataset
n_epochs = 50           # its the round of learning in Dataset means the learning process involves the model seeing and learning from the entire dataset ten times
batch_size = 32          # this one was 32 i change it to 500
shuffle_buffer_size = 10000
prefetch_buffer_size = 1

def preprocess(dataframe):
    """Flatten a batch `pixels` and return the features as an `OrderedDict`."""
    def map_fn(dataset):
        return collections.OrderedDict(
            x=tf.cast(dataset[:,:-1], tf.float64),
            y=tf.cast(tf.reshape(dataset[:,-1], shape=(-1, 1)), tf.int64)
        )
    return tf.data.Dataset.from_tensor_slices(dataframe).repeat(n_epochs).shuffle(
        shuffle_buffer_size).batch(batch_size).map(map_fn).prefetch(prefetch_buffer_size)

# Now that 'train' is defined, this should work
client_data = [preprocess(train.sample(n=n_samples)) for _ in range(n_workers)]

# Assuming you have a 'unique_codes' variable
unique_codes = train.iloc[:, -1].unique()
unique_codes = unique_codes.astype(int)  # Convert to integers

# Assuming you have a 'mapping' variable for yticks labels
mapping = {k: str(k) for k in unique_codes}  # Replace with your actual mapping

fig = plt.figure(figsize=(20, 7))
fig.suptitle('Label Counts for a Sample of Worker Data')
fig.tight_layout()

for i in range(n_workers):
    m = 0
    plot_data = collections.defaultdict(list)
    for label in list(client_data[i].take(1))[0]['y'].numpy()[:, 0]:
        plot_data[label].append(label)
        m = max(m, len(plot_data[label]))

    n_cols = n_workers if n_workers < 5 else 5
    xlim = [0, m + (5 - m % 5)]
    ylim = [min(unique_codes) - 1, max(unique_codes) + 1]
    yticks = list(range(min(unique_codes), max(unique_codes) + 1))
    yticks_labels = [mapping[k] for k in yticks]

    plt.subplot(int(n_workers / 5) + 1, n_cols, i + 1)
    plt.subplots_adjust(wspace=0.3)
    plt.title('Worker {}'.format(i + 1))
    plt.xlabel('#points')
    plt.xlim(xlim)
    plt.ylabel('Label')
    plt.ylim(ylim)
    plt.yticks(yticks, labels=yticks_labels)

    for key in plot_data:
        if len(plot_data[key]) > 0:
            plt.text(len(plot_data[key]) + 0.6, int(key) - 0.1, str(len(plot_data[key])), ha='center')

    for j in range(min(unique_codes), max(unique_codes) + 1):
        plt.hist(
            plot_data[j],
            density=False,
            bins=[k - 0.5 for k in range(min(unique_codes), max(unique_codes) + 2)],
            orientation='horizontal'
        )

plt.show()

"""## Define the Model to Train

The model we use is a simple MLP with one hidden layer. // keep this note in case i want to retrun the MLP Code again i saved it under MLP reimplement code from FL

The code below is the DRL code Which I integrated in FL for training  instead of MLP Deep learning algoithem with
"""

import gym
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import random
from collections import deque
import pandas as pd

# Define the DQN Network
class DQN(nn.Module):
    def __init__(self, input_dim, output_dim):
        super(DQN, self).__init__()
        self.fc1 = nn.Linear(input_dim, 128)
        self.fc2 = nn.Linear(128, 128)
        self.fc3 = nn.Linear(128, output_dim)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.relu(x)
        x = self.fc3(x)
        return x

# Define the DQN Agent
class DQNAgent:
    def __init__(self, state_dim, action_dim):
        self.state_dim = state_dim
        self.action_dim = action_dim
        self.epsilon = 1.0
        self.epsilon_min = 0.01
        self.epsilon_decay = 0.995
        self.gamma = 0.99
        self.learning_rate = 0.001
        self.batch_size = 64
        self.memory = deque(maxlen=2000)
        self.policy_net = DQN(state_dim, action_dim)
        self.target_net = DQN(state_dim, action_dim)
        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate)
        self.update_target_network()

    def update_target_network(self):
        self.target_net.load_state_dict(self.policy_net.state_dict())

    def select_action(self, state):
        if np.random.rand() <= self.epsilon:
            return random.randrange(self.action_dim)
        state = torch.FloatTensor(state).unsqueeze(0)
        with torch.no_grad():
            q_values = self.policy_net(state)
        return np.argmax(q_values.numpy())

    def remember(self, state, action, reward, next_state, done):
        self.memory.append((state, action, reward, next_state, done))

    def replay(self):
        if len(self.memory) < self.batch_size:
            return
        batch = random.sample(self.memory, self.batch_size)
        for state, action, reward, next_state, done in batch:
            target = reward
            if not done:
                next_state = torch.FloatTensor(next_state).unsqueeze(0)
                target = reward + self.gamma * torch.max(self.target_net(next_state)).item()
            state = torch.FloatTensor(state).unsqueeze(0)
            target_f = self.policy_net(state)
            target_f[0][action] = target
            self.optimizer.zero_grad()
            loss = nn.MSELoss()(target_f, self.policy_net(state))
            loss.backward()
            self.optimizer.step()
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

# Integration with the Environment

# Make sure this function is indented correctly at the same level as the class definitions
def main(train_data):
    # Ensure train_data has a 'label' column
    if 'label' not in train_data.columns:
        # Add a 'label' column (replace with your actual label generation logic)
        train_data['label'] = np.random.randint(0, 2, size=len(train_data))

    # You will need to define or import DRL_IDS_Env and Trainer

"""## Set Up the Remote Executors

By default, TFF executes all computations locally. In this step we tell TFF to connect to another (set of) client(s).

Verify the integrity of the IP address(es) and port(s) before initiating connection and training.

This is only needed in a cloud set up.
"""

# Simulated local training function for a client
def local_train(client_data, global_state):
    model = global_state  # Assuming global_state is your model

    # Load client data
    data_loader = DataLoader(client_data, batch_size=32, shuffle=True)

    # Set model to training mode
    model.train()

    total_loss = 0
    all_predictions = []
    all_labels = []

    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Example optimizer
    loss_function = nn.CrossEntropyLoss()  # Example loss function

    for batch in data_loader:
        inputs, labels = batch  # Ensure batch contains inputs and labels

        # Forward pass
        outputs = model(inputs.float())  # Assuming input data is float

        # Compute loss
        loss = loss_function(outputs, labels)
        total_loss += loss.item()

        # Backward pass and optimization
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Store predictions and labels
        preds = outputs.argmax(dim=1)
        all_predictions.extend(preds.tolist())
        all_labels.extend(labels.tolist())

    # Compute metrics
    accuracy, precision, recall, f1 = compute_metrics(np.array(all_predictions), np.array(all_labels))
    avg_loss = total_loss / len(data_loader)

    # Store metrics
    train_metrics = {
        'loss': avg_loss,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1
    }

    # Return updated state and metrics
    return {
        'state': model.state_dict(),  # Return model state dict
        'metrics': train_metrics
    }

"""calculated the measuersments"""

import time
import adamp
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler

# Enhanced Model
class EnhancedModel(nn.Module):
    def __init__(self):
        super(EnhancedModel, self).__init__()
        self.fc1 = nn.Linear(10, 128)
        self.fc2 = nn.Linear(128, 256)
        self.fc3 = nn.Linear(256, 128)
        self.fc4 = nn.Linear(128, 10)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)
        self.batch_norm1 = nn.BatchNorm1d(128)
        self.batch_norm2 = nn.BatchNorm1d(256)
        self.batch_norm3 = nn.BatchNorm1d(128)

    def forward(self, x):
        x = self.fc1(x)
        x = self.batch_norm1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.batch_norm2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.batch_norm3(x)
        x = self.relu(x)
        x = self.fc4(x)
        return x

class Trainer:
    def initialize(self):
        return EnhancedModel()

trainer = Trainer()

def compute_metrics(predictions, labels):
    correct_predictions = (predictions == labels).sum()
    total_predictions = len(labels)
    accuracy = correct_predictions / total_predictions
    precision = precision_score(labels, predictions, average='weighted', zero_division=0)
    recall = recall_score(labels, predictions, average='weighted', zero_division=0)
    f1 = f1_score(labels, predictions, average='weighted', zero_division=0)
    return accuracy, precision, recall, f1

def local_train(client_data, client_labels, global_state):
    model = global_state
    data_loader = DataLoader(TensorDataset(client_data, client_labels), batch_size=64, shuffle=True)
    model.train()
    total_loss = 0
    all_predictions = []
    all_labels = []

    optimizer = adamp.AdamP(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)
    loss_function = nn.CrossEntropyLoss()

    for inputs, labels in data_loader:
        outputs = model(inputs.float())
        loss = loss_function(outputs, labels)
        total_loss += loss.item()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        preds = outputs.argmax(dim=1)
        all_predictions.extend(preds.tolist())
        all_labels.extend(labels.tolist())

    scheduler.step(total_loss / len(data_loader))
    accuracy, precision, recall, f1 = compute_metrics(np.array(all_predictions), np.array(all_labels))
    avg_loss = total_loss / len(data_loader)
    train_metrics = {'loss': avg_loss, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}
    return {'state': model.state_dict(), 'metrics': train_metrics}

def aggregate(global_state, client_results):
    model = global_state
    with torch.no_grad():
        for key in model.state_dict().keys():
            avg_param = torch.stack([client['state'][key].float() for client in client_results], dim=0).mean(dim=0)
            model.state_dict()[key].copy_(avg_param)
    aggregated_metrics = {
        'loss': sum(client_result['metrics']['loss'] for client_result in client_results) / len(client_results),
        'accuracy': sum(client_result['metrics']['accuracy'] for client_result in client_results) / len(client_results),
        'precision': sum(client_result['metrics']['precision'] for client_result in client_results) / len(client_results),
        'recall': sum(client_result['metrics']['recall'] for client_result in client_results) / len(client_results),
        'f1': sum(client_result['metrics']['f1'] for client_result in client_results) / len(client_results)
    }
    return model, aggregated_metrics

def evaluate(num_rounds=150, num_clients=5):
    global_state = trainer.initialize()
    scaler = StandardScaler()
    client_data = [torch.rand(100, 10) for _ in range(num_clients)]
    client_labels = [torch.randint(0, 10, (100,)) for _ in range(num_clients)]

    client_data = [torch.tensor(scaler.fit_transform(client), dtype=torch.float32) for client in client_data]

    best_accuracy = 0
    best_round = 0
    patience = 15
    early_stopping_counter = 0

    for round in range(num_rounds):
        t1 = time.time()
        client_results = [local_train(client_data[i], client_labels[i], global_state) for i in range(num_clients)]
        global_state, train_metrics = aggregate(global_state, client_results)

        accuracy = train_metrics['accuracy'] * 100
        precision = train_metrics['precision']
        recall = train_metrics['recall']
        f1 = train_metrics['f1']
        t2 = time.time()

        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_round = round
            early_stopping_counter = 0
            print(f"New best accuracy: {best_accuracy:.2f}% at round {round+1}")
        else:
            early_stopping_counter += 1

        if early_stopping_counter >= patience:
            print(f"Early stopping at round {round+1}")
            break

        print('Round {}: accuracy {:.2f}%, precision {:.4f}, recall {:.4f}, f1-score {:.4f}, round time {:.2f}s'.format(
            round+1, accuracy, precision, recall, f1, t2 - t1))

    print(f"Best accuracy achieved: {best_accuracy:.2f}% at round {best_round+1}")

evaluate()

# vusioual results
import matplotlib.pyplot as plt

# Assuming fl_accuracies, fl_precisions, fl_recalls, fl_f1s are lists containing metric values across episodes
# If you haven't collected these metrics yet, you'll need to do so in your training loop.
# Here's a placeholder:

fl_accuracies = []  # Replace with your actual accuracy values
fl_precisions = []  # Replace with your actual precision values
fl_recalls = []     # Replace with your actual recall values
fl_f1s = []         # Replace with your actual F1-score values

# Plot results
plt.figure(figsize=(12, 8))

# FL Accuracy
plt.subplot(2, 2, 1)
plt.plot(fl_accuracies)
plt.xlabel('Episode')
plt.ylabel('FL Accuracy')
plt.title('Episode vs FL Accuracy')

# FL Precision
plt.subplot(2, 2, 2)
plt.plot(fl_precisions)
plt.xlabel('Episode')
plt.ylabel('FL Precision')
plt.title('Episode vs FL Precision')

# FL Recall
plt.subplot(2, 2, 3)
plt.plot(fl_recalls)
plt.xlabel('Episode')
plt.ylabel('FL Recall')
plt.title('Episode vs FL Recall')

# FL F1-score
plt.subplot(2, 2, 4)
plt.plot(fl_f1s)
plt.xlabel('Episode')
plt.ylabel('FL F1-score')
plt.title('Episode vs FL F1-score')

plt.tight_layout()
plt.show()

#import grpc

#ip_address = ['0.0.0.0'] * n_workers  #@param {type:"string"}
#ports = [80+i for i in range(n_workers)]  #@param {type:list["integer"]}

#channels = [grpc.insecure_channel(f'{ip_address[i]}:{ports[i]}') for i in range(len(ports))]

#tff.backends.native.set_remote_python_execution_context(channels)

"""### Launch N TFF workers as Docker Containers locally

```
docker run --rm -p 80:8000 -v /home/:/home/ gcr.io/tensorflow-federated/remote-executor-service:latest
docker run --rm -p 81:8000 -v /home/:/home/ gcr.io/tensorflow-federated/remote-executor-service:latest
docker run --rm -p 82:8000 -v /home/:/home/ gcr.io/tensorflow-federated/remote-executor-service:latest
...
```


Or use the **docker-compose.yaml** file to launch $2 \leq N \leq 5$ TFF workers as Docker Containers locally
```
docker compose up --scale tff=2
```
"""

import matplotlib.pyplot as plt
import time
import adamp
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler

# Enhanced Model
class EnhancedModel(nn.Module):
    def __init__(self):
        super(EnhancedModel, self).__init__()
        self.fc1 = nn.Linear(10, 128)
        self.fc2 = nn.Linear(128, 256)
        self.fc3 = nn.Linear(256, 128)
        self.fc4 = nn.Linear(128, 10)
        self.relu = nn.ReLU()
        self.dropout = nn.Dropout(0.5)
        self.batch_norm1 = nn.BatchNorm1d(128)
        self.batch_norm2 = nn.BatchNorm1d(256)
        self.batch_norm3 = nn.BatchNorm1d(128)

    def forward(self, x):
        x = self.fc1(x)
        x = self.batch_norm1(x)
        x = self.relu(x)
        x = self.fc2(x)
        x = self.batch_norm2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.fc3(x)
        x = self.batch_norm3(x)
        x = self.relu(x)
        x = self.fc4(x)
        return x

class Trainer:
    def initialize(self):
        return EnhancedModel()

trainer = Trainer()

def compute_metrics(predictions, labels):
    correct_predictions = (predictions == labels).sum()
    total_predictions = len(labels)
    accuracy = correct_predictions / total_predictions
    precision = precision_score(labels, predictions, average='weighted', zero_division=0)
    recall = recall_score(labels, predictions, average='weighted', zero_division=0)
    f1 = f1_score(labels, predictions, average='weighted', zero_division=0)
    return accuracy, precision, recall, f1

def local_train(client_data, client_labels, global_state):
    model = global_state
    data_loader = DataLoader(TensorDataset(client_data, client_labels), batch_size=64, shuffle=True)
    model.train()
    total_loss = 0
    all_predictions = []
    all_labels = []

    optimizer = adamp.AdamP(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)
    loss_function = nn.CrossEntropyLoss()

    for inputs, labels in data_loader:
        outputs = model(inputs.float())
        loss = loss_function(outputs, labels)
        total_loss += loss.item()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        preds = outputs.argmax(dim=1)
        all_predictions.extend(preds.tolist())
        all_labels.extend(labels.tolist())

    scheduler.step(total_loss / len(data_loader))
    accuracy, precision, recall, f1 = compute_metrics(np.array(all_predictions), np.array(all_labels))
    avg_loss = total_loss / len(data_loader)
    train_metrics = {'loss': avg_loss, 'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1}
    return {'state': model.state_dict(), 'metrics': train_metrics}

def aggregate(global_state, client_results):
    model = global_state
    with torch.no_grad():
        for key in model.state_dict().keys():
            avg_param = torch.stack([client['state'][key].float() for client in client_results], dim=0).mean(dim=0)
            model.state_dict()[key].copy_(avg_param)
    aggregated_metrics = {
        'loss': sum(client_result['metrics']['loss'] for client_result in client_results) / len(client_results),
        'accuracy': sum(client_result['metrics']['accuracy'] for client_result in client_results) / len(client_results),
        'precision': sum(client_result['metrics']['precision'] for client_result in client_results) / len(client_results),
        'recall': sum(client_result['metrics']['recall'] for client_result in client_results) / len(client_results),
        'f1': sum(client_result['metrics']['f1'] for client_result in client_results) / len(client_results)
    }
    return model, aggregated_metrics

def evaluate(num_rounds=150, num_clients=5):
    global_state = trainer.initialize()
    scaler = StandardScaler()
    client_data = [torch.rand(100, 10) for _ in range(num_clients)]
    client_labels = [torch.randint(0, 10, (100,)) for _ in range(num_clients)]

    client_data = [torch.tensor(scaler.fit_transform(client), dtype=torch.float32) for client in client_data]

    best_accuracy = 0
    best_round = 0
    patience = 15
    early_stopping_counter = 0

    fl_accuracies = []   # List to store accuracy values across episodes
    fl_precisions = []   # List to store precision values across episodes
    fl_recalls = []      # List to store recall values across episodes
    fl_f1s = []          # List to store F1-score values across episodes

    for round in range(num_rounds):
        t1 = time.time()
        client_results = [local_train(client_data[i], client_labels[i], global_state) for i in range(num_clients)]
        global_state, train_metrics = aggregate(global_state, client_results)

        accuracy = train_metrics['accuracy'] * 100
        precision = train_metrics['precision']
        recall = train_metrics['recall']
        f1 = train_metrics['f1']

        fl_accuracies.append(accuracy)   # Append accuracy for plotting
        fl_precisions.append(precision)  # Append precision for plotting
        fl_recalls.append(recall)        # Append recall for plotting
        fl_f1s.append(f1)                # Append F1-score for plotting

        t2 = time.time()

        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_round = round
            early_stopping_counter = 0
            print(f"New best accuracy: {best_accuracy:.2f}% at round {round+1}")
        else:
            early_stopping_counter += 1

        if early_stopping_counter >= patience:
            print(f"Early stopping at round {round+1}")
            break

        print('Round {}: accuracy {:.2f}%, precision {:.4f}, recall {:.4f}, f1-score {:.4f}, round time {:.2f}s'.format(
            round+1, accuracy, precision, recall, f1, t2 - t1))

    print(f"Best accuracy achieved: {best_accuracy:.2f}% at round {best_round+1}")

    # Plot results
    plt.figure(figsize=(12, 8))

    # FL Accuracy
    plt.subplot(2, 2, 1)
    plt.plot(fl_accuracies)
    plt.xlabel('Episode')
    plt.ylabel('FL Accuracy')
    plt.title('Episode vs FL Accuracy')

    # FL Precision
    plt.subplot(2, 2, 2)
    plt.plot(fl_precisions)
    plt.xlabel('Episode')
    plt.ylabel('FL Precision')
    plt.title('Episode vs FL Precision')

    # FL Recall
    plt.subplot(2, 2, 3)
    plt.plot(fl_recalls)
    plt.xlabel('Episode')
    plt.ylabel('FL Recall')
    plt.title('Episode vs FL Recall')

    # FL F1-score
    plt.subplot(2, 2, 4)
    plt.plot(fl_f1s)
    plt.xlabel('Episode')
    plt.ylabel('FL F1-score')
    plt.title('Episode vs FL F1-score')

    plt.tight_layout()
    plt.show()

evaluate()

"""## Run Training"""

evaluate(n_epochs)

"""Obviously the training evaluation results are not that great, but further optimization and hyperparameters fine-tuning can be done.

new code to fix the accurancy
"""

